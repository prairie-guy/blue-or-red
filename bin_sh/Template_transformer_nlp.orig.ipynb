{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855ccc90",
   "metadata": {},
   "source": [
    "## Learning about NLP Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d2b658",
   "metadata": {},
   "source": [
    "### Kaggle Competition: U.S. Patent Phrase to Phrase Matching\n",
    "https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/data?select=train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9668712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:12:25.560699Z",
     "start_time": "2022-05-31T04:12:23.269812Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66a04e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:12:25.602868Z",
     "start_time": "2022-05-31T04:12:25.599547Z"
    }
   },
   "outputs": [],
   "source": [
    "from rich import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a21835",
   "metadata": {},
   "source": [
    "### Examine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d8e561a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:30:46.875559Z",
     "start_time": "2022-05-31T04:30:46.868850Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path(\"us-patent-phrase-to-phrase-matching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d8e22e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:30:52.475779Z",
     "start_time": "2022-05-31T04:30:52.421938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     anchor                  target context  score\n",
       "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n",
       "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n",
       "2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n",
       "3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n",
       "4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654393e",
   "metadata": {},
   "source": [
    "### Create and Preprocess DataFrame\n",
    "Concanenate records into a single document and add to `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d9a67c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:12:52.909081Z",
     "start_time": "2022-05-31T04:12:52.875911Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TEXT1: A47; TEXT2: abatement of pollution ;ANC1; abatement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>TEXT1: A47; TEXT2: act of abating ;ANC1; abatement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>TEXT1: A47; TEXT2: active catalyst ;ANC1; abatement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TEXT1: A47; TEXT2: eliminating process ;ANC1; abatement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>TEXT1: A47; TEXT2: forest region ;ANC1; abatement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     anchor                  target context  score  \\\n",
       "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n",
       "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n",
       "2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n",
       "3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50   \n",
       "4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00   \n",
       "\n",
       "                                                        input  \n",
       "0  TEXT1: A47; TEXT2: abatement of pollution ;ANC1; abatement  \n",
       "1          TEXT1: A47; TEXT2: act of abating ;ANC1; abatement  \n",
       "2         TEXT1: A47; TEXT2: active catalyst ;ANC1; abatement  \n",
       "3     TEXT1: A47; TEXT2: eliminating process ;ANC1; abatement  \n",
       "4           TEXT1: A47; TEXT2: forest region ;ANC1; abatement  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['input'] = \"TEXT1: \" + df.context + \"; TEXT2: \" + df.target + \" ;ANC1; \" + df.anchor\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89004c8",
   "metadata": {},
   "source": [
    "### Create Dataset from DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05dfa051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:14:38.544497Z",
     "start_time": "2022-05-31T04:14:38.374339Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6317a1e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:14:44.036049Z",
     "start_time": "2022-05-31T04:14:43.999156Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b927b4b",
   "metadata": {},
   "source": [
    "### Tokenize Dataset\n",
    "Need to know the `model` in order to get the correct Tokenizer with `AutoTokenizer(model)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47b7449c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:15:25.525335Z",
     "start_time": "2022-05-31T04:15:25.441850Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45c4fd6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:15:27.939702Z",
     "start_time": "2022-05-31T04:15:27.932832Z"
    }
   },
   "outputs": [],
   "source": [
    "model_nm = 'microsoft/deberta-v3-small'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c9492",
   "metadata": {},
   "source": [
    "**It is important that the tokenizer used for the training is the same as used for new documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b85e744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:15:37.148233Z",
     "start_time": "2022-05-31T04:15:34.379697Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/cdaniels/mambaforge/envs/fastai/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokz = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4443c5",
   "metadata": {},
   "source": [
    "Here's a simple function which tokenizes our inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3963324b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:15:41.218325Z",
     "start_time": "2022-05-31T04:15:41.210443Z"
    }
   },
   "outputs": [],
   "source": [
    "def tok_func(x): return tokz(x[\"input\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286c74d",
   "metadata": {},
   "source": [
    "Map `tok_func` on `ds['input']`, which uses `tokz` to tokenize each element. This creates a tokenized dataset `tok_ds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a8bfd01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:17:29.083204Z",
     "start_time": "2022-05-31T04:17:27.876765Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da868d19dd994b3b8cf03055f74b942d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_ds = ds.map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2280f28",
   "metadata": {},
   "source": [
    "#### The labelcolumn name needs to be`labels`.  Need to rename `score` to `labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9428e77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:19:22.568017Z",
     "start_time": "2022-05-31T04:19:22.556072Z"
    }
   },
   "outputs": [],
   "source": [
    "tok_ds = tok_ds.rename_columns({'score':'labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e11082af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:19:34.322261Z",
     "start_time": "2022-05-31T04:19:34.307448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '37d61fd2272659b1',\n",
       " 'anchor': 'abatement',\n",
       " 'target': 'abatement of pollution',\n",
       " 'context': 'A47',\n",
       " 'labels': 0.5,\n",
       " 'input': 'TEXT1: A47; TEXT2: abatement of pollution ;ANC1; abatement',\n",
       " 'input_ids': [1,\n",
       "  54453,\n",
       "  435,\n",
       "  294,\n",
       "  336,\n",
       "  5753,\n",
       "  346,\n",
       "  54453,\n",
       "  445,\n",
       "  294,\n",
       "  47284,\n",
       "  265,\n",
       "  6435,\n",
       "  2600,\n",
       "  64097,\n",
       "  435,\n",
       "  346,\n",
       "  47284,\n",
       "  2],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed768b55",
   "metadata": {},
   "source": [
    "### Create the Training and Test/Valid datasets from tok_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1e92cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T00:33:08.029512Z",
     "start_time": "2022-05-31T00:33:08.017497Z"
    }
   },
   "source": [
    "`DatasetDict` here, `dds` holds training and validation datasets. To create one that contains 25% of our data for the validation set, and 75% for the training set, use `train_test_split`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "839bcf82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:21:30.056420Z",
     "start_time": "2022-05-31T04:21:30.032597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 27354\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds = tok_ds.train_test_split(.25) # DataSetDict\n",
    "dds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00962bf1",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c50cf1",
   "metadata": {},
   "source": [
    "Pearson coefficient between (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1341ffe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:21:37.917981Z",
     "start_time": "2022-05-31T04:21:37.909497Z"
    }
   },
   "outputs": [],
   "source": [
    "def corr(x,y): return np.corrcoef(x,y)[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f36bdd",
   "metadata": {},
   "source": [
    "Transformers expects metrics to be returned as a `dict`, since that way the trainer knows what label to use, so let's create a function to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3602184a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:21:41.291660Z",
     "start_time": "2022-05-31T04:21:41.284577Z"
    }
   },
   "outputs": [],
   "source": [
    "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a725bfb5",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a111cefb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:34:04.279395Z",
     "start_time": "2022-05-31T04:34:04.271470Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee89dc60",
   "metadata": {},
   "source": [
    "Another Auto Factory Method using the `model_nm` to create a model consisitent with the `AutoTokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a253a0a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:26:07.371321Z",
     "start_time": "2022-05-31T04:26:04.735352Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/config.json from cache at /home/cdaniels/.cache/huggingface/transformers/8e0c12a7672d1d36f647c86e5fc3a911f189d8704e2bc94dde4a1ffe38f648fa.9df96bac06c2c492bc77ad040068f903c93beec14607428f25bf9081644ad0da\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/pytorch_model.bin from cache at /home/cdaniels/.cache/huggingface/transformers/ce3185000148731a86ceaf533caa85fe513fc79e02b7fe5831fb1ed52a0e0d22.7e73b1561275ae3b633ba76ab7e4889d28d73dbcdc008cbc2414369b39da319b\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841721b2",
   "metadata": {},
   "source": [
    "### Create Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70f01351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:26:22.350788Z",
     "start_time": "2022-05-31T04:26:22.343986Z"
    }
   },
   "outputs": [],
   "source": [
    "bs = 128\n",
    "epochs = 2\n",
    "lr = 8e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbf5916",
   "metadata": {},
   "source": [
    "All of the paramaters related to the `Trainer` go into `TrainerArguments`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a083c4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:26:25.611283Z",
     "start_time": "2022-05-31T04:26:25.599847Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c2ae7f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:26:29.425654Z",
     "start_time": "2022-05-31T04:26:29.268462Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
    "                  tokenizer=tokz, compute_metrics=corr_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a7b8aa",
   "metadata": {},
   "source": [
    "### Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fb66acf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:29:58.167337Z",
     "start_time": "2022-05-31T04:27:35.563139Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, anchor, id, input, target. If context, anchor, id, input, target are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/cdaniels/mambaforge/envs/fastai/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 27354\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 214\n",
      "/home/cdaniels/mambaforge/envs/fastai/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='214' max='214' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [214/214 02:19, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.033595</td>\n",
       "      <td>0.768747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.026450</td>\n",
       "      <td>0.801013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, anchor, id, input, target. If context, anchor, id, input, target are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9119\n",
      "  Batch size = 512\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, anchor, id, input, target. If context, anchor, id, input, target are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9119\n",
      "  Batch size = 512\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ecd4c5",
   "metadata": {},
   "source": [
    "### Create Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6087cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:57:29.197832Z",
     "start_time": "2022-05-31T03:57:29.182022Z"
    }
   },
   "source": [
    "Use `eval` as our name for the test set, to avoid confusion with the `test` dataset that was created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e7272a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:35:33.760571Z",
     "start_time": "2022-05-31T04:35:33.741941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>opc drum</td>\n",
       "      <td>inorganic photoconductor drum</td>\n",
       "      <td>G02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>adjust gas flow</td>\n",
       "      <td>altering gas flow</td>\n",
       "      <td>F23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>lower trunnion</td>\n",
       "      <td>lower locating</td>\n",
       "      <td>B60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>cap component</td>\n",
       "      <td>upper portion</td>\n",
       "      <td>D06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>neural stimulation</td>\n",
       "      <td>artificial neural network</td>\n",
       "      <td>H04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id              anchor                         target context\n",
       "0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02\n",
       "1  09e418c93a776564     adjust gas flow              altering gas flow     F23\n",
       "2  36baf228038e314b      lower trunnion                 lower locating     B60\n",
       "3  1f37ead645e7f0c8       cap component                  upper portion     D06\n",
       "4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv(path/'test.csv')\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3924140b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:35:39.814892Z",
     "start_time": "2022-05-31T04:35:39.805213Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e2f81fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:35:44.096948Z",
     "start_time": "2022-05-31T04:35:44.038791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2729114a551b43b98d1b7d36802781a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5bcf3e",
   "metadata": {},
   "source": [
    "### Prediction and Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e005c5",
   "metadata": {},
   "source": [
    "Use `trainer.predict(eval_ds)` to make predictions on the `eval_ds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e3116ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:36:07.059872Z",
     "start_time": "2022-05-31T04:36:06.705021Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context, anchor, id, input, target. If context, anchor, id, input, target are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.53369141],\n",
       "       [ 0.69970703],\n",
       "       [ 0.33984375],\n",
       "       [ 0.39233398],\n",
       "       [-0.02444458],\n",
       "       [ 0.52636719],\n",
       "       [ 0.33374023],\n",
       "       [ 0.09204102],\n",
       "       [ 0.16113281],\n",
       "       [ 1.12304688],\n",
       "       [ 0.18237305],\n",
       "       [ 0.36230469],\n",
       "       [ 0.734375  ],\n",
       "       [ 0.70458984],\n",
       "       [ 0.79394531],\n",
       "       [ 0.45092773],\n",
       "       [ 0.17443848],\n",
       "       [ 0.06079102],\n",
       "       [ 0.546875  ],\n",
       "       [ 0.2310791 ],\n",
       "       [ 0.38452148],\n",
       "       [ 0.25097656],\n",
       "       [ 0.12054443],\n",
       "       [ 0.18103027],\n",
       "       [ 0.54248047],\n",
       "       [-0.04666138],\n",
       "       [ 0.01157379],\n",
       "       [ 0.00126743],\n",
       "       [ 0.01052094],\n",
       "       [ 0.79150391],\n",
       "       [ 0.19909668],\n",
       "       [ 0.07568359],\n",
       "       [ 0.69628906],\n",
       "       [ 0.35449219],\n",
       "       [ 0.36962891],\n",
       "       [ 0.1973877 ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = trainer.predict(eval_ds).predictions.astype(float)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30a230c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:36:27.194516Z",
     "start_time": "2022-05-31T04:36:27.182210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53369141],\n",
       "       [0.69970703],\n",
       "       [0.33984375],\n",
       "       [0.39233398],\n",
       "       [0.        ],\n",
       "       [0.52636719],\n",
       "       [0.33374023],\n",
       "       [0.09204102],\n",
       "       [0.16113281],\n",
       "       [1.        ],\n",
       "       [0.18237305],\n",
       "       [0.36230469],\n",
       "       [0.734375  ],\n",
       "       [0.70458984],\n",
       "       [0.79394531],\n",
       "       [0.45092773],\n",
       "       [0.17443848],\n",
       "       [0.06079102],\n",
       "       [0.546875  ],\n",
       "       [0.2310791 ],\n",
       "       [0.38452148],\n",
       "       [0.25097656],\n",
       "       [0.12054443],\n",
       "       [0.18103027],\n",
       "       [0.54248047],\n",
       "       [0.        ],\n",
       "       [0.01157379],\n",
       "       [0.00126743],\n",
       "       [0.01052094],\n",
       "       [0.79150391],\n",
       "       [0.19909668],\n",
       "       [0.07568359],\n",
       "       [0.69628906],\n",
       "       [0.35449219],\n",
       "       [0.36962891],\n",
       "       [0.1973877 ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.clip(preds, 0, 1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eeb884",
   "metadata": {},
   "source": [
    "### Create our CSV Submission Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e87a642",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:36:35.524516Z",
     "start_time": "2022-05-31T04:36:35.478277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb054dfc55a842ce8ba883aa4f995d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1059"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "submission = datasets.Dataset.from_dict({\n",
    "    'id': eval_ds['id'],\n",
    "    'score': preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8300999",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T04:36:39.711579Z",
     "start_time": "2022-05-31T04:36:39.692026Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>[0.53369141]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>[0.69970703]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>[0.33984375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>[0.39233398]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>[0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>474c874d0c07bd21</td>\n",
       "      <td>[0.52636719]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>442c114ed5c4e3c9</td>\n",
       "      <td>[0.33374023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b8ae62ea5e1d8bdb</td>\n",
       "      <td>[0.09204102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>faaddaf8fcba8a3f</td>\n",
       "      <td>[0.16113281]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ae0262c02566d2ce</td>\n",
       "      <td>[1.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a8808e31641e856d</td>\n",
       "      <td>[0.18237305]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16ae4b99d3601e60</td>\n",
       "      <td>[0.36230469]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25c555ca3d5a2092</td>\n",
       "      <td>[0.734375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5203a36c501f1b7c</td>\n",
       "      <td>[0.70458984]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b9fdc772bb8fd61c</td>\n",
       "      <td>[0.79394531]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7aa5908a77a7ec24</td>\n",
       "      <td>[0.45092773]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>d19ef3979396d47e</td>\n",
       "      <td>[0.17443848]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fd83613b7843f5e1</td>\n",
       "      <td>[0.06079102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2a619016908bfa45</td>\n",
       "      <td>[0.546875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>733979d75f59770d</td>\n",
       "      <td>[0.2310791]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6546846df17f9800</td>\n",
       "      <td>[0.38452148]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3ff0e7a35015be69</td>\n",
       "      <td>[0.25097656]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12ca31f018a2e2b9</td>\n",
       "      <td>[0.12054443]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>03ba802ed4029e4d</td>\n",
       "      <td>[0.18103027]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>c404f8b378cbb008</td>\n",
       "      <td>[0.54248047]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>78243984c02a72e4</td>\n",
       "      <td>[0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>de51114bc0faec3e</td>\n",
       "      <td>[0.01157379]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7e3aff857f056bf9</td>\n",
       "      <td>[0.00126743]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>26c3c6dc6174b589</td>\n",
       "      <td>[0.01052094]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>b892011ab2e2cabc</td>\n",
       "      <td>[0.79150391]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8247ff562ca185cc</td>\n",
       "      <td>[0.19909668]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>c057aecbba832387</td>\n",
       "      <td>[0.07568359]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9f2279ce667b21dc</td>\n",
       "      <td>[0.69628906]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>b9ea2b06a878df6f</td>\n",
       "      <td>[0.35449219]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>79795133c30ef097</td>\n",
       "      <td>[0.36962891]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>25522ee5411e63e9</td>\n",
       "      <td>[0.1973877]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id         score\n",
       "0   4112d61851461f60  [0.53369141]\n",
       "1   09e418c93a776564  [0.69970703]\n",
       "2   36baf228038e314b  [0.33984375]\n",
       "3   1f37ead645e7f0c8  [0.39233398]\n",
       "4   71a5b6ad068d531f          [0.]\n",
       "5   474c874d0c07bd21  [0.52636719]\n",
       "6   442c114ed5c4e3c9  [0.33374023]\n",
       "7   b8ae62ea5e1d8bdb  [0.09204102]\n",
       "8   faaddaf8fcba8a3f  [0.16113281]\n",
       "9   ae0262c02566d2ce          [1.]\n",
       "10  a8808e31641e856d  [0.18237305]\n",
       "11  16ae4b99d3601e60  [0.36230469]\n",
       "12  25c555ca3d5a2092    [0.734375]\n",
       "13  5203a36c501f1b7c  [0.70458984]\n",
       "14  b9fdc772bb8fd61c  [0.79394531]\n",
       "15  7aa5908a77a7ec24  [0.45092773]\n",
       "16  d19ef3979396d47e  [0.17443848]\n",
       "17  fd83613b7843f5e1  [0.06079102]\n",
       "18  2a619016908bfa45    [0.546875]\n",
       "19  733979d75f59770d   [0.2310791]\n",
       "20  6546846df17f9800  [0.38452148]\n",
       "21  3ff0e7a35015be69  [0.25097656]\n",
       "22  12ca31f018a2e2b9  [0.12054443]\n",
       "23  03ba802ed4029e4d  [0.18103027]\n",
       "24  c404f8b378cbb008  [0.54248047]\n",
       "25  78243984c02a72e4          [0.]\n",
       "26  de51114bc0faec3e  [0.01157379]\n",
       "27  7e3aff857f056bf9  [0.00126743]\n",
       "28  26c3c6dc6174b589  [0.01052094]\n",
       "29  b892011ab2e2cabc  [0.79150391]\n",
       "30  8247ff562ca185cc  [0.19909668]\n",
       "31  c057aecbba832387  [0.07568359]\n",
       "32  9f2279ce667b21dc  [0.69628906]\n",
       "33  b9ea2b06a878df6f  [0.35449219]\n",
       "34  79795133c30ef097  [0.36962891]\n",
       "35  25522ee5411e63e9   [0.1973877]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6388a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
